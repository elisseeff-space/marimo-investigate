# =============================================================================
# LLM Configuration - Simple Mode (Recommended)
# =============================================================================
# Use LLM_DEFAULT_PROVIDER + LLM_MODEL for simple configuration
# Provider-specific settings are automatically applied

# Provider: azure, openai, openrouter, anthropic, ollama, mistral, lmstudio
LLM_DEFAULT_PROVIDER=openrouter

# Model: Any model available from the selected provider
LLM_MODEL=qwen/qwen3-235b-a22b-thinking-2507

# =============================================================================
# Provider-Specific API Keys
# =============================================================================
# Set the API key for your chosen provider

# OpenRouter API Key
OPENROUTER_API_KEY=sk-or-v1-your-key-here

# OpenRouter Extra Headers (optional, for rankings on openrouter.ai)
# OPENROUTER_SITE_URL=https://your-site.com
# OPENROUTER_SITE_NAME=Your Site Name

# OpenAI API Key
# LLM_OPENAI_API_KEY=sk-your-key-here

# Anthropic API Key
# LLM_ANTHROPIC_API_KEY=sk-ant-your-key-here

# Mistral API Key
# LLM_MISTRAL_API_KEY=your-key-here

# Azure OpenAI (requires URL and key)
# LLM_AZURE_API_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment/chat/completions
# LLM_AZURE_API_KEY=your-key-here

# Ollama (local, no API key needed)
# LLM_OLLAMA_API_URL=http://localhost:11434

# LM Studio (local, no API key needed)
# LLM_LMSTUDIO_API_URL=http://localhost:1234/v1

# Generic OpenAI-compatible API
# LLM_COMPATIBLE_API_URL=http://localhost:8080/v1
# LLM_COMPATIBLE_API_KEY=not-needed

# =============================================================================
# LLM Configuration - Benchmark Mode (Advanced)
# =============================================================================
# Use LLM_DEFAULT_MODEL for predefined model configurations
# Comment out LLM_DEFAULT_PROVIDER and LLM_MODEL to use this mode

# LLM_DEFAULT_MODEL=qwen3-235b-a22b-thinking-2507
# LLM_QWEN3_235B_A22B_THINKING_2507_PROVIDER=openrouter
# LLM_QWEN3_235B_A22B_THINKING_2507_MODEL=qwen/qwen3-235b-a22b-thinking-2507
# LLM_QWEN3_235B_A22B_THINKING_2507_KEY_ENV=OPENROUTER_API_KEY

# =============================================================================
# Default Response Model (Structured Output)
# =============================================================================
# All LLM queries will return this schema by default
# Options: GovernmentDocumentExtraction, or leave empty for unstructured output

LLM_DEFAULT_RESPONSE_MODEL=GovernmentDocumentExtraction

# =============================================================================
# Optional Settings
# =============================================================================

# Sampling temperature (0-2)
LLM_TEMPERATURE=0.7

# Maximum tokens in response (empty = model default)
# LLM_MAX_TOKENS=4096

# Number of retry attempts for failed requests
LLM_MAX_RETRIES=3

# Request timeout in seconds
LLM_TIMEOUT=60

# Disable caching (true/false)
LLM_NOCACHE=false

# Cache directory
# LLM_CACHE_DIR=workspace/cache/llm

# Cache TTL in seconds (0 = no expiration)
# LLM_CACHE_TTL=0

# =============================================================================
# Rate Limiting
# =============================================================================

# Requests per minute (0 = no limit)
LLM_RATE_LIMIT_RPM=60

# Minimum delay between requests (seconds)
# LLM_RATE_LIMIT_DELAY=0.0

# =============================================================================
# Retry Configuration
# =============================================================================

# Base delay for exponential backoff (seconds)
# LLM_RETRY_BASE_DELAY=2.0

# Maximum delay between retries (seconds)
# LLM_RETRY_MAX_DELAY=60.0

# =============================================================================
# Adaptive Throttling
# =============================================================================

# Enable adaptive throttling (true/false)
# LLM_THROTTLE_ENABLED=true

# Minimum RPM factor when throttling (0.25 = 25% of configured RPM)
# LLM_THROTTLE_MIN_FACTOR=0.25

# Time before trying to increase RPM (seconds)
# LLM_THROTTLE_RECOVERY_TIME=60.0

# =============================================================================
# Circuit Breaker
# =============================================================================

# Enable circuit breaker (true/false)
# LLM_CIRCUIT_BREAKER_ENABLED=true

# Number of consecutive failures to open circuit
# LLM_CIRCUIT_FAILURE_THRESHOLD=5

# Time before half-open test (seconds)
# LLM_CIRCUIT_RECOVERY_TIME=30.0
